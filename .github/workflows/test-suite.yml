name: Test Suite

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  PYTHON_VERSION: '3.11'
  MIN_COVERAGE: 80

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: testuser
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: aiteddy_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Set up test environment
      env:
        DATABASE_URL: postgresql://testuser:testpass@localhost:5432/aiteddy_test
        REDIS_URL: redis://localhost:6379/0
        SECRET_KEY: test-secret-key-for-ci
        OPENAI_API_KEY: test-api-key
      run: |
        echo "Test environment configured"
    
    - name: Run linting
      run: |
        # Run flake8 for Python linting
        flake8 src/ tests/ --max-line-length=100 --extend-ignore=E203,W503
        
        # Run black for formatting check
        black --check src/ tests/
    
    - name: Run type checking
      run: |
        mypy src/ --ignore-missing-imports --no-strict-optional
    
    - name: Run security checks
      run: |
        # Check for security vulnerabilities
        pip install safety
        safety check --json
        
        # Check for hardcoded secrets
        pip install bandit
        bandit -r src/ -ll
    
    - name: Run unit tests
      env:
        DATABASE_URL: postgresql://testuser:testpass@localhost:5432/aiteddy_test
        REDIS_URL: redis://localhost:6379/0
        SECRET_KEY: test-secret-key-for-ci
        OPENAI_API_KEY: test-api-key
      run: |
        pytest tests/unit/ -v --tb=short --cov=src --cov-report=xml --cov-report=term
    
    - name: Run integration tests
      env:
        DATABASE_URL: postgresql://testuser:testpass@localhost:5432/aiteddy_test
        REDIS_URL: redis://localhost:6379/0
        SECRET_KEY: test-secret-key-for-ci
        OPENAI_API_KEY: test-api-key
      run: |
        pytest tests/integration/ -v --tb=short
    
    - name: Run E2E tests
      env:
        DATABASE_URL: postgresql://testuser:testpass@localhost:5432/aiteddy_test
        REDIS_URL: redis://localhost:6379/0
        SECRET_KEY: test-secret-key-for-ci
        OPENAI_API_KEY: test-api-key
      run: |
        pytest tests/e2e/ -v --tb=short -m "not slow"
    
    - name: Check test coverage
      run: |
        coverage report --fail-under=${{ env.MIN_COVERAGE }}
        coverage html
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
    
    - name: Upload coverage HTML report
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: coverage-report
        path: htmlcov/
    
    - name: Check for skipped tests
      run: |
        SKIPPED=$(grep -r "@pytest.mark.skip" tests/ | wc -l)
        if [ $SKIPPED -gt 0 ]; then
          echo "❌ Found $SKIPPED skipped tests!"
          grep -r "@pytest.mark.skip" tests/
          exit 1
        fi
        echo "✅ No skipped tests found"
    
    - name: Performance test baseline
      if: github.event_name == 'push' && github.ref == 'refs/heads/main'
      run: |
        pytest tests/performance/ --benchmark-only --benchmark-json=benchmark.json || true
    
    - name: Upload performance results
      if: github.event_name == 'push' && github.ref == 'refs/heads/main'
      uses: actions/upload-artifact@v3
      with:
        name: performance-benchmark
        path: benchmark.json

  mutation-testing:
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install mutmut
    
    - name: Run mutation testing
      env:
        DATABASE_URL: sqlite:///test.db
      run: |
        # Run mutation testing on critical modules
        mutmut run --paths-to-mutate=src/application/services/child_safety/ \
                   --tests-dir=tests/unit/ \
                   --runner="pytest -x -q" || true
        
        # Generate report
        mutmut results
    
    - name: Upload mutation test results
      uses: actions/upload-artifact@v3
      with:
        name: mutation-test-results
        path: .mutmut-cache

  test-report:
    runs-on: ubuntu-latest
    needs: [test, mutation-testing]
    if: always()
    
    steps:
    - name: Download artifacts
      uses: actions/download-artifact@v3
    
    - name: Generate test summary
      run: |
        echo "# Test Summary Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f coverage-report/index.html ]; then
          echo "## Coverage Report" >> $GITHUB_STEP_SUMMARY
          echo "Coverage report has been generated and uploaded as an artifact." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -f performance-benchmark/benchmark.json ]; then
          echo "## Performance Benchmark" >> $GITHUB_STEP_SUMMARY
          echo "Performance benchmarks have been recorded." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "## Next Steps" >> $GITHUB_STEP_SUMMARY
        echo "- Review coverage report for gaps" >> $GITHUB_STEP_SUMMARY
        echo "- Check mutation testing results" >> $GITHUB_STEP_SUMMARY
        echo "- Verify all critical paths are tested" >> $GITHUB_STEP_SUMMARY