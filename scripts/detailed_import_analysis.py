#!/usr/bin/env python3
"""ØªØ­Ù„ÙŠÙ„ Ù…ÙØµÙ„ Ù„Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ù…Ø¹ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„Ù„Ø­Ù„ÙˆÙ„"""

import os
import ast
import sys
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional
from collections import defaultdict

class DetailedImportAnalyzer:
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.src_path = self.project_root / "src"
        self.tests_path = self.project_root / "tests"
        self.missing_imports = defaultdict(list)
        self.import_solutions = {}
        self.existing_modules = set()
        
    def scan_existing_modules(self):
        """Ù…Ø³Ø­ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"""
        for base_path in [self.src_path, self.tests_path]:
            if base_path.exists():
                for py_file in base_path.glob("**/*.py"):
                    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø³Ø§Ø± Ø¥Ù„Ù‰ import path
                    relative_path = py_file.relative_to(self.project_root)
                    parts = list(relative_path.parts)
                    
                    if py_file.name == "__init__.py":
                        module_path = ".".join(parts[:-1])
                    else:
                        parts[-1] = parts[-1].replace(".py", "")
                        module_path = ".".join(parts)
                    
                    self.existing_modules.add(module_path)
                    
                    # Ù…Ø³Ø­ Ù…Ø­ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ù„Ù Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª ÙˆØ§Ù„Ø¯ÙˆØ§Ù„
                    try:
                        with open(py_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                        tree = ast.parse(content)
                        
                        for node in ast.walk(tree):
                            if isinstance(node, ast.ClassDef):
                                self.existing_modules.add(f"{module_path}.{node.name}")
                            elif isinstance(node, ast.FunctionDef):
                                self.existing_modules.add(f"{module_path}.{node.name}")
                    except:
                        pass
    
    def find_similar_modules(self, missing_import: str) -> List[str]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙˆØ­Ø¯Ø§Øª Ù…Ø´Ø§Ø¨Ù‡Ø© Ù„Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙÙ‚ÙˆØ¯"""
        similar = []
        missing_parts = missing_import.lower().split('.')
        
        for module in self.existing_modules:
            module_parts = module.lower().split('.')
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ØªØ·Ø§Ø¨Ù‚ Ø¬Ø²Ø¦ÙŠ
            if any(part in module_parts for part in missing_parts[-2:]):
                similar.append(module)
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø³Ù…Ø§Ø¡ Ù…Ø´Ø§Ø¨Ù‡Ø©
            if missing_parts[-1] in module_parts[-1] or module_parts[-1] in missing_parts[-1]:
                similar.append(module)
        
        return list(set(similar))[:5]  # Ø£Ø¹Ù„Ù‰ 5 Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª
    
    def analyze_missing_import(self, import_name: str) -> Dict[str, any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…ÙÙ‚ÙˆØ¯ ÙˆØ¥ÙŠØ¬Ø§Ø¯ Ø­Ù„ÙˆÙ„ Ù…Ø­ØªÙ…Ù„Ø©"""
        analysis = {
            'import': import_name,
            'type': self.classify_import(import_name),
            'suggestions': [],
            'possible_locations': []
        }
        
        # Ø¥ÙŠØ¬Ø§Ø¯ ÙˆØ­Ø¯Ø§Øª Ù…Ø´Ø§Ø¨Ù‡Ø©
        similar = self.find_similar_modules(import_name)
        if similar:
            analysis['suggestions'] = similar
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© Ù„Ù„Ù…Ù„Ù
        parts = import_name.split('.')
        if parts[0] in ['src', 'tests']:
            base_path = self.project_root / parts[0]
            
            # Ù…Ø³Ø§Ø±Ø§Øª Ù…Ø­ØªÙ…Ù„Ø©
            possible_paths = [
                base_path / '/'.join(parts[1:]) / '__init__.py',
                base_path / '/'.join(parts[1:-1]) / f"{parts[-1]}.py",
            ]
            
            analysis['possible_locations'] = [str(p.relative_to(self.project_root)) 
                                            for p in possible_paths]
        
        return analysis
    
    def classify_import(self, import_name: str) -> str:
        """ØªØµÙ†ÙŠÙ Ù†ÙˆØ¹ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯"""
        if import_name.startswith('src.core'):
            return 'Core Domain'
        elif import_name.startswith('src.application'):
            return 'Application Layer'
        elif import_name.startswith('src.infrastructure'):
            return 'Infrastructure Layer'
        elif import_name.startswith('src.interfaces'):
            return 'Interfaces'
        elif import_name.startswith('src.shared'):
            return 'Shared/DTO'
        elif import_name.startswith('tests'):
            return 'Test Module'
        else:
            return 'External'
    
    def generate_fix_script(self):
        """ØªÙˆÙ„ÙŠØ¯ Ø³ÙƒØ±ÙŠØ¨Øª Ù„Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©"""
        fixes = []
        
        for file_path, missing_list in self.missing_imports.items():
            for import_name, line_no in missing_list:
                analysis = self.analyze_missing_import(import_name)
                
                if analysis['suggestions']:
                    fixes.append({
                        'file': file_path,
                        'line': line_no,
                        'old_import': import_name,
                        'suggested_import': analysis['suggestions'][0],
                        'type': analysis['type']
                    })
        
        return fixes
    
    def run_detailed_analysis(self):
        """ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØµÙ„"""
        print("ğŸ” Ù…Ø³Ø­ Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©...")
        self.scan_existing_modules()
        print(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(self.existing_modules)} ÙˆØ­Ø¯Ø©")
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª
        python_files = []
        for base_path in [self.src_path, self.tests_path]:
            if base_path.exists():
                python_files.extend(base_path.glob("**/*.py"))
        
        print(f"\nğŸ“„ ØªØ­Ù„ÙŠÙ„ {len(python_files)} Ù…Ù„Ù Python...")
        
        for file_path in sorted(python_files):
            self.analyze_file(file_path)
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…ÙØµÙ„Ø©
        self.display_detailed_results()
    
    def analyze_file(self, file_path: Path):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù ÙˆØ§Ø­Ø¯"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        if not self.check_import_exists(alias.name):
                            self.missing_imports[str(file_path)].append((alias.name, node.lineno))
                            
                elif isinstance(node, ast.ImportFrom):
                    module = node.module or ''
                    full_import = module
                    
                    if not self.check_import_exists(full_import) and (
                        full_import.startswith('src.') or full_import.startswith('tests.')):
                        self.missing_imports[str(file_path)].append((full_import, node.lineno))
        except:
            pass
    
    def check_import_exists(self, import_name: str) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯"""
        if import_name.startswith('src.') or import_name.startswith('tests.'):
            # ØªØ­Ù‚Ù‚ Ø¨Ø³ÙŠØ· Ù…Ù† Ø§Ù„ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙˆØ­Ø¯Ø§Øª
            return any(module.startswith(import_name) for module in self.existing_modules)
        return True
    
    def display_detailed_results(self):
        """Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…ÙØµÙ„Ø©"""
        if not self.missing_imports:
            print("\nâœ… Ù„Ø§ ØªÙˆØ¬Ø¯ Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ù…ÙÙ‚ÙˆØ¯Ø©!")
            return
        
        print("\n" + "="*80)
        print("ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ù…ÙØµÙ„ Ù„Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©")
        print("="*80)
        
        # ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
        by_type = defaultdict(list)
        all_missing = []
        
        for file_path, missing_list in self.missing_imports.items():
            for import_name, line_no in missing_list:
                import_type = self.classify_import(import_name)
                by_type[import_type].append({
                    'file': Path(file_path).relative_to(self.project_root),
                    'import': import_name,
                    'line': line_no
                })
                all_missing.append(import_name)
        
        # Ø¹Ø±Ø¶ Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
        for import_type, items in sorted(by_type.items()):
            print(f"\nğŸ“¦ {import_type} ({len(items)} Ø§Ø³ØªÙŠØ±Ø§Ø¯)")
            print("-" * 60)
            
            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©
            import_count = defaultdict(list)
            for item in items:
                import_count[item['import']].append((item['file'], item['line']))
            
            for import_name, locations in sorted(import_count.items()):
                print(f"\n  âŒ {import_name}")
                analysis = self.analyze_missing_import(import_name)
                
                if analysis['suggestions']:
                    print(f"     ğŸ’¡ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª:")
                    for sugg in analysis['suggestions'][:3]:
                        print(f"        - {sugg}")
                
                print(f"     ğŸ“ Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:")
                for file_path, line_no in locations[:3]:
                    print(f"        - {file_path}:{line_no}")
                
                if len(locations) > 3:
                    print(f"        ... Ùˆ {len(locations) - 3} Ù…ÙˆÙ‚Ø¹ Ø¢Ø®Ø±")
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù†Ù‡Ø§Ø¦ÙŠØ©
        print("\n" + "="*80)
        print("ğŸ“ˆ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
        print(f"   - Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ØªØ£Ø«Ø±Ø©: {len(self.missing_imports)}")
        print(f"   - Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©: {len(all_missing)}")
        print(f"   - Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ø§Ù„ÙØ±ÙŠØ¯Ø© Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©: {len(set(all_missing))}")
        
        # ØªÙˆÙ„ÙŠØ¯ Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ø¥ØµÙ„Ø§Ø­
        fixes = self.generate_fix_script()
        if fixes:
            print(f"\nğŸ”§ ÙŠÙ…ÙƒÙ† Ø¥ØµÙ„Ø§Ø­ {len(fixes)} Ø§Ø³ØªÙŠØ±Ø§Ø¯ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹")
            print("   Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„: python scripts/auto_fix_imports.py")

if __name__ == "__main__":
    project_root = "/mnt/c/Users/jaafa/Desktop/ai teddy bear"
    analyzer = DetailedImportAnalyzer(project_root)
    analyzer.run_detailed_analysis()